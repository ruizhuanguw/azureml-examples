{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed PyTorch Lightning with Horovod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "\n",
    "# get root of git repo\n",
    "prefix = Path(git.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "# training script\n",
    "source_dir = prefix.joinpath(\n",
    "    \"code\", \"models\", \"pytorch-lightning\", \"mnist-autoencoder\"\n",
    ")\n",
    "script_name = \"train.py\"\n",
    "\n",
    "# environment file\n",
    "environment_file = prefix.joinpath(\"environments\", \"pt-lightning-horovod.yml\")\n",
    "\n",
    "# azure ml settings\n",
    "environment_name = \"pt-lightning-horovod\"\n",
    "experiment_name = \"pt-lightning-horovod-example\"\n",
    "cluster_name = \"gpu-k80-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open(source_dir.joinpath(script_name)).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.from_conda_specification(environment_name, environment_file)\n",
    "\n",
    "# specify a GPU base image\n",
    "env.docker.enabled = True\n",
    "env.docker.base_image = (\n",
    "    \"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and run training job\n",
    "Create a ScriptRunConfig to specify the training script & arguments, environment, and cluster to run on.\n",
    "\n",
    "To use Horovod for distributed training with PyTorch Lightning, specify the distributed mode, in this case `\"horovod\"`, to the `--distributed_backend` argument. To enable GPU training, set `--gpus=1`. Note that this is just to configure Lightning to use GPUs for training rather than CPUs, which is the default if `--gpus` is not set. \n",
    "\n",
    "To actually configure the number of GPUs per node and number of nodes for your training job, specify that information using with the MpiConfiguration object. Azure ML will use this information to configure the number of worker processes with the driver application (*mpirun*) that it uses to start the job.\n",
    "\n",
    "For more information on using Horovod with Lightning, see the [documentation](https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html#horovod)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import ScriptRunConfig, Experiment\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "cluster = ws.compute_targets[cluster_name]\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=source_dir,\n",
    "    script=script_name,\n",
    "    arguments=[\"--max_epochs\", 25, \"--gpus\", 1, \"--distributed_backend\", \"horovod\"],\n",
    "    compute_target=cluster,\n",
    "    environment=env,\n",
    "    distributed_job_config=MpiConfiguration(process_count_per_node=4, node_count=1),\n",
    ")\n",
    "\n",
    "run = Experiment(ws, experiment_name).submit(src)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-sdk)",
   "language": "python",
   "name": "aml-sdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
